!pip install pmdarima

# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from pmdarima import auto_arima  # Automatically select ARIMA order
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.optimizers import Adam

# Load the dataset
data = pd.read_csv('Tesla.csv')
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

# Handle missing values
data.ffill(inplace=True)

# Visualize data
plt.figure(figsize=(10, 6))
plt.plot(data['Close'], label='Close Price', color='blue')
plt.title('Stock Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price ($)')
plt.legend()
plt.grid()
plt.show()

# Stationarity Test (ADF)
result = adfuller(data['Close'])
print(f"ADF Statistic: {result[0]}")
print(f"p-value: {result[1]}")
if result[1] <= 0.05:
    print("The data is stationary.")
else:
    print("The data is not stationary. Differencing may be required.")

# --- ARIMA Forecasting ---
# Automatically find the best ARIMA order
auto_arima_model = auto_arima(data['Close'], seasonal=False, trace=True, suppress_warnings=True)
print(auto_arima_model.summary())

# Fit the ARIMA model with selected order
arima_model = ARIMA(data['Close'], order=auto_arima_model.order)
arima_result = arima_model.fit()

# Forecast next 30 days
forecast = arima_result.get_forecast(steps=30)
forecast_mean = forecast.predicted_mean
forecast_ci = forecast.conf_int()

# Plot ARIMA forecast
plt.figure(figsize=(12, 6))
plt.plot(data['Close'], label='Actual Prices', color='green')
plt.plot(forecast_mean.index, forecast_mean, label='Forecast Prices', color='red')
plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='pink', alpha=0.3)
plt.title('ARIMA Model - Stock Price Forecast')
plt.xlabel('Date')
plt.ylabel('Price ($)')
plt.legend()
plt.grid()
plt.show()

# --- LSTM Forecasting ---
# Scale data to [0, 1]
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))

# Create train and test datasets
train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

# Create sequences for LSTM
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

seq_length = 60  # Use last 60 days to predict the next day
X_train, y_train = create_sequences(train_data, seq_length)
X_test, y_test = create_sequences(test_data, seq_length)

# Reshape input for LSTM (samples, timesteps, features)
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Define the improved LSTM model
model = Sequential([
    # First Bidirectional LSTM layer with BatchNorm
    Bidirectional(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], 1))),
    BatchNormalization(),
    Dropout(0.2),
    
    # Second Bidirectional LSTM layer with BatchNorm
    Bidirectional(LSTM(units=100, return_sequences=True)),
    BatchNormalization(),
    Dropout(0.2),
    
    # Third Bidirectional LSTM layer with BatchNorm
    Bidirectional(LSTM(units=100)),
    BatchNormalization(),
    Dropout(0.2),
    
    # Output Dense layer
    Dense(units=1)
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# Callbacks for training
callbacks = [
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, verbose=1),
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)
]

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    callbacks=callbacks,
    verbose=1
)

# Predict the test data
predicted_prices = model.predict(X_test)
predicted_prices = scaler.inverse_transform(predicted_prices)

# Plot the predictions
plt.figure(figsize=(10, 6))
plt.plot(data.index[train_size + seq_length:], scaler.inverse_transform(test_data[seq_length:]), label='Actual Price', color='blue')
plt.plot(data.index[train_size + seq_length:], predicted_prices, label='Predicted Price', color='red')
plt.title('LSTM Stock Price Prediction')
plt.xlabel('Date')
plt.ylabel('Price ($)')
plt.legend()
plt.grid()
plt.show()

# Evaluation Metrics
mse = mean_squared_error(scaler.inverse_transform(y_test.reshape(-1, 1)), predicted_prices)
rmse = np.sqrt(mse)
print(f'Mean Squared Error: {mse}')
print(f'Root Mean Squared Error: {rmse}')
